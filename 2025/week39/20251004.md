## Tasks
1. Finish the simulation:
   1. ~~Min_finder_batch: 4 Blocks~~
   2. ~~intermediate_fifo: 4 blocks~~
   3. filter buffer: 4 Blocks
   4. ~~Global Merger: 4 Blocks~~
   5. ~~PE: 4 Blocks~~
   6. smallest_ticker_finder: 4 Blocks
   7. output queue: 8 Blocks
   8. core: 6 blocks
   9. conv_layer: 6 blocks.
   10. Convert raw data to dram version. 6 Blocks.


## timeline-schedule
1. ~~8:30-9:05 Task 1.1 part 1~~
2. ~~9:05-9:40 part 2~~
3. 15:40-16:25 task 1.3
4.  16:25-17:10 part 2
5.  17:10-17:45 part 3
6.  17:45-18:20 part 4
7.  18:20-19:00 Rest
8.  19:00-19:35 task 1.4 part 1
9.  19:35-20:10 task 1.4 part 2
10. 20:10-20:45 part 3
11. 20:45-21:20 part 4
12. 21:20-21:55 task 1.5 part 1
13. 21:55-22:30 task 1.5 part 2

## timeline-schedule v2
1. ~~16:00-16:35 global merger part 1~~
2. ~~16:35-17:10 part 2~~
3. 17:10-17:45 part 3
4. 17:45-18:20 part 4
5. Go out and buy tomorrow's eating stuff (羊汤again嘿嘿)
6. 19:00-19:35 filter buffer part 1
7. 19:35-20:20 filter buffer part 2
8. 20:20-21:05 filter buffer part 3
9. 21:05-21:40 filter buffer part 4
10. 21:40-22:25 PE part 1
11. 22:25-23:10 PE part 2
12. 23:10-23:45 PE part 3
13. 23:45-00:20 PE part 4


### Task 1.1
Try to think about which functions are needed. What parameters is needed. Where are they from.
1. For input spine buffer, it has two three functions:
    1. pre-load the logic spine id to the physical input spine buffer.
        * **Parameters needed:** An array of logical spine id of first batch. Layer id.
          *  **An array of logical spine id of first batch:** Layer's computation of a map: [[batch0: spine 0, spine 1, spine 2, ..., spine x], [batch1: spine a, spine b, ..., ], ..., [batch needed: spine x, spine y, spine z, ...]]--> Send to the core. Spine_buffer uses the member from the core.
          *  **Layer id:**  Layer's layer id.-->Send to the core.
        * **How to Implement:** Once recived the array of the logical spine id, 
          * Check the array size is less than or equals to the number of the physical buffer.
          * Iterate through physical buffer, use dram.LoadInputSpine(layer_id, spine_id, &input buffer[i], max_bytes = input_buffer.size) 
    2. In run function, if needed, load next batch's spine ids' to the physical spine buffer.
        * **Parameters needed:** An array of logical spine id of current batch. Layer id. current_batch_cursor.
          *  **current_batch_cursor.**: core will hold a current batch.
          *  **Layer id:**  Layer's layer id.-->Send to the core.
          *  **An array of logical spine id of current batch:** grab from core's map: map[batch_cursor]
          *  **How to implement:** 
            *  First check whether it is needed to load data from dram by checking whether the current batch cursor is less than batch needed.
            *  Check if all the buffer is empty, which is the pre-requisite of loading data.
            *  Check the array size is less than or equals to the number of the physical buffer.
            *  Iterate through physical buffer, use dram.LoadInputSpine(layer_id, spine_id, &input buffer[i], max_bytes = input_buffer.size)   
    3. Give the Entry with the smallest time steps to the min_finder_batch
        * **Parameters needed:** No
        * **How to implement:**
          * **Output: one Entry with smallest time steps**
          * Iterate through the input_spine_buffer, compare their header, pop the one with the smallest time steps.
2. For min_finder_batch, 
   1. it should have the following members:
      1. a pointer to the input_spine_buffer.
      2. a pointer to an array of Intermediate fifo.
      3. An entry to receive the picked entry.
      4. An true/false flag to determine if the last batch's first entry is pushed to the intermediate fifo.
   2. it should have two function: 
      1. run() which contains the two following functions:
         1. select the entry with the smallest time steps from the 16 header.
              * **Parameters needed:** a reference to input_spine_buffer's PopSmallestTsEntry(), an empty entry to store the poped Entry
                * a reference to input_spine_buffer's PopSmallestTsEntry(): from the reference of input_spine_buffer;
                *  **Entry:** internal variable
              * **How to Implement:** Use the function in the input spine buffer. 
         2. push the selected enty to the related intermediate fifo.
              * **Parameters needed:** current batch cursor, the reference of intermediate fifo's push(function), the Entry before.
                * current batch cursor: From core;
                * the reference of intermediate fifo's push: from intermediate_fifo.
                * The filled Entry.
              * **How to Implement:** 
                * First check the current cursor.
                * Then use the current batch cursor find the intermediate fifo in the array.
                * push the entry to that intermediate fifo 
         3. If the flag is already true, then we ignore it. else: If current_cursor == batch_needed, and the entry is successfully pushed to the intermediate fifo, then set the fifo to true.
      2. CanGlobalMegerWork()
            * **Parameters needed:** None
            * **How to Implement:** Return the flag.
3. For intermediate_fifo,
   1. it should have the following members:
      1. buf_[Capacities]. The Capacities should be part of common/constants.hpp
4. For Global Merger:
   1. Member:
      1. a reference to intermediate fifo
      2. a reference to min_finder_batch
   2. Function:
      1. It should have a function run()  
        * **Parameters needed:** 
          * A reference to MinFinderBatch's CanGlobalMergerWork() from min_finder_batch
          * An reference of Entry to receive the Entry.
        *  **How to implement:** 
          *  First check if it can work by using "CanGlobalMergerWork()"
          *  Then iterate through intermediate fifo (Actually it is the intermediate fifo belonging to the min_finder_batch), pop the smallest Entry.
5. For PE Array:
   1. Member:
      1. Entry to store the entry poped by GlobalMerger
      2. Weight Row Grabbed from the filter buffer
      3. An Array of PE
      4. An output array of Entries to store the output spiked entry for one time.
   2. Function:
      1. Iterate through the pe before the while loop of spinal flow, assign the output id and threshold to each pe.
        * **Parameters needed:** 
          * Threshold (From core)
          * tile index (from the core)
          * position number h, position number w (from core)
          * W (from the layer)
          * member: (pe array)
        *  **How to implement:** 
          *  Iterate through the the 128 pe, 
             *  Compute the output id := tile number * (h *W + w) * 128 + pe_idx, assign the pe.output_neuron_id with the computed value.
             *  set the threshold to pe.
      2. Get the entry poped by global merger: GetInputEntryFromGM():
        * **Parameters needed:** 
          * An Entry.
        *  **How to implement:** 
          *  Assign the member variable by the output of the global merger.
      3. Find the weight row for computation: GetWeightRow():
        * **Parameters needed:**
          * member: Entry->neuron_id
          * a reference to filter buffer: It will compute the row id based on the sent neuron_id (by function ComputeRowId), then use the function GetRow(), getting a list of weight.
          * member: row(A list of weight): receive the list of weight.
        * **How to implement:**
          * filter_buffer.GetRow(filter_buffer.ComputeRowId(Entry->neuron_id))  
      4. run:
        * **Parameters needed:** 
        *  **How to implement:** 
          *  GetInputEntryFromGM(), get the input entry
          *  GetWeightRow(), get the weight row
          *  Iterate through the pe, set the parameter into pe, do the computation. If it is spiked, push the generated entry to the output array of entries. 
6. PE:
   1. Member:
     * Vmem
     * Threshold
     * output_neuron_id
     * spiked (bool)
   2. Functions:
      1. RegisterOutputId()
        **Parameter needed:**
         * outputId (From pe_array)
        **How to Implement:**
         * Assign the outputId to its member
      2. SetThreshold()
        **Parameter needed:**
         * threshold (From pe_array)
        **How to Implement:**
         * Assign the threshold to its member
      3.  Process()
        **Parameter needed:**
         * time steps
         * weight
        **How to Implement:**
         * Vmem += weight 
         * If Vmem >= threshold, reset Vmem to 0, then set spiked to true, and generate an Entry <time steps, output neuron id>
7. For Filter Buffer:
   1. Member:
      1. An array of weight row of 128 weight, weight is uint8_t, the total size of the array is 4068 rows.
      2. outh
      3. outw
      4. outW
      5. Input channel number
   2. Function:
      1. UpdateParameter():
        * **Parameters needed:** 
          * h (From core)
          * w (From core)
          * W (From core)
          * Input channel number (From core)-->(From layer)
        * **How to implement:**
          * the member variables are directly assigned by the input parameter.
      2. ComputeRowId()
        * **Parameters needed:** 
          * A neuron id
        * **How to implement:**
          * Since the neuron id is like this: channel number * (h *W + w) +  pe_idx, we only need to do neuron_id % (h * W + w), and we get the channel index
          * with the channel index, we just compute channel index * (h * W + w), and get the row id.
      3. GetRow()
        * **Parameters needed:**
          * A row id
        * **How to implement:**
          * Return the row id's data by the row id
      4. LoadWeightFromDram(tile idx):
        * **Parameters needed:** 
          * tile idx (From core)-->(From Layer?) (not sure)
          * Layer idx (From Layer)
        * **How to implement:**
          * Use LoadWeightTile to load data.
8. 


