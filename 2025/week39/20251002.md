## Tasks
1. ~~Change back DRAM to the one with OUTPUT type. 6 Blocks~~
2. ~~Change the output_queue. 6-8 Blocks.~~
3. Do the data transformation part. 6-8 Blocks.
4. Latency Design.

### Task 1
#### Goal
1. Try to change the DRAM back to the previous version.
   1. Check file in dram.

#### Result
1. Finished stream_reader change and dram_common/ segment header.
#### Block 1



### Task 2
#### Goal
1. Check what they provide, understand the following tasks.

#### Result
1. Block 1:


## Tasks
1. Check the input spine buffer's function, change the load part to a really simple one. 4 blocks.
2. Check the filter buffer, do the same thing. 4 blocks.
3. Check the output buffer, do the same thing. 4 blocks.

### Task 1
#### Goal
1. Go through the input spine buffer, check what is needed, the interface between dram and input spine buffer.


#### Result
1. For input_spine_buffer, it need to
   1. Load spine from dram to the input_spine_buffer.
   Load(spine_id):
        dram.Load(layer, spine id, size, &input_spine_buffer[i])
      1. For this part, they need to provide the spine id to the dram, and dram will use the spine id to copy the data back to the input_spine_address. The spine id is determined by the conv_layer, sent from conv_runner to core to input spine buffer.
   2. feed the entries in the buffer to the comparator tree. 


Conv_layer()
    Configure the filter buffer
    For output spine from 0 to [H, W]
        For tile from [0 to output channel/128]
           1. Load Weight of this layer
           2. compute the an array of spine ids, compute the total batches needed, generate a table sorted by batches
                  (e.g. batch 0[spine 0, spine 1, spine 2, ... spine 15]
                        batch 1[spine 21, spine 22, spine 23, ... , spine n])
           3. pre-Load input spines from dram:
               1. pre-Load First batch:
                  1. dispatch the logical id to each input spine buffer, dram.Load(Layer, Type = input, spine_id, size, &input_spine_buffer[i])
               2. set the threshold and output_neuron_id for pe in pe_array
           4. Update the filter buffer's h_out, w_out  
           5. While (not finished):
                 1. Stage 0 store tiled output buffer.
                 2. Stage 2 Compute the pe array.
                 3. Stage 3 min_finder_batch drain from input spine buffer and push to intermediate fifo.
                 4. Stage 5 Load other batches from DRAM if needed.  dram.Load(Layer, spine_id, size, &input_spine_buffer[i])
       1. Do the tile sort, generate the final output spine
       2. Store the spine. Dram.Store(spine id, Layer, size, store address). Then update the next time store address:= current store address + size.
DRAM layout format: 
Layer:
    Input:
        Spine 0, Spine 1, Spine 2, ... , Spine 512 (if it has 512 Spine)
    Weight:
        [tile][input channel][h][w][0-127]
    Output:
        Spine 0, Spine 1, Spine 2, ... , Spine 512 (if it has 512 Spine)


DRAM should have a table for each input spines' id, start address, size. So for load(layer id, input spine, spine id), it will directly find the spine id's address and size, and do memcpy.


   
